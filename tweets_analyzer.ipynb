{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEUpacJCrgDM",
        "outputId": "ce812c07-ecc7-48f0-abbe-4e6e5fa8a7d0"
      },
      "outputs": [],
      "source": [
        "!pip install nltk -q\n",
        "!pip install gensim -q\n",
        "!pip install wordcloud -q\n",
        "!pip install emoji -q\n",
        "!python -m spacy download pt_core_news_sm -q\n",
        "!pip install pyLDAvis -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fi7I2fhkCNl",
        "outputId": "a6a66257-bf12-4310-adbe-3a87f0eefd25"
      },
      "outputs": [],
      "source": [
        "# IMPORTAÇÃO DAS BIBLIOTECAS\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import emoji\n",
        "import spacy \n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "from gensim import corpora, models\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "pd.options.mode.chained_assignment = None  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvVcd8QHRh_C",
        "outputId": "56fe2161-3213-41b9-9689-ef2291a2b08f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R14D0H5f0dH8"
      },
      "outputs": [],
      "source": [
        "# LEITURA DO DATAFRAME COM PANDAS\n",
        "data = pd.read_csv('/content/drive/MyDrive/PesquisaCovid/db_lemmatizado/db_2020-02-01_2020-03-31__lematizado.csv', \n",
        "                   engine='python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "nyN8NrwUl0wO",
        "outputId": "6fbc4faf-7a14-4ceb-a774-2633288a8b6b"
      },
      "outputs": [],
      "source": [
        "data = data.loc[0:1000]\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em7Cl9L5uYq4"
      },
      "outputs": [],
      "source": [
        "# FUNÇÕES PARA CONTAGEM DE TWEETS DE ACORDO COM USUÁRIO\n",
        "\n",
        "# Função para filtrar a conta do usuário \n",
        "def filtra_users(text):\n",
        "  aux = 0\n",
        "  posicao = 0\n",
        "  text_temp = str(text)\n",
        "  text_temp = text_temp.split()\n",
        "  for word in text_temp:\n",
        "    aux = aux + 1\n",
        "    if (word == \"'username':\"):\n",
        "      posicao = aux\n",
        "  text_temp = text_temp[posicao]\n",
        "  text_temp = re.sub(r\"[',]\", ' ', text_temp)\n",
        "  return text_temp\n",
        "\n",
        "# Função para agrupar todos os usuários em um único arquivo de texto\n",
        "all_users = []\n",
        "def agrupa_users(text):\n",
        "  all_users.append(text)\n",
        "\n",
        "# Função para contar todos os usuários em um único arquivo de texto\n",
        "def conta_tweets_user(text): \n",
        "  text_temp = text.strip()\n",
        "  str_all_users = ''.join(all_users)\n",
        "  return str_all_users.count(text_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0d56bTmQuYog",
        "outputId": "15a22737-3bd9-4578-935e-223b040b3c10"
      },
      "outputs": [],
      "source": [
        "# REALIZANDO A CONTAGEM DE TWEETS POR USUÁRIO\n",
        "# ATENÇÃO: A CELULA DEVE SER EXECUTADA UMA ÚNICA VEZ POR ACESSO\n",
        "\n",
        "# Renomeando a coluna content_lemmatizada em full_text\n",
        "data = data.rename(columns={'content_lemmatizada': 'full_text'})\n",
        "\n",
        "# Criação de um novo dataframe com os dados do usuário\n",
        "df = data[['full_text','user']]\n",
        "\n",
        "# Aplicando a função para filtrar o nome de usuário dos dados\n",
        "df['conta'] = df['user'].apply(filtra_users)\n",
        "\n",
        "# Entrada de dados para agrupamento de todos os usuários\n",
        "df['conta'].apply(agrupa_users)\n",
        "\n",
        "# Função para contagem dos usúarios no agrupamento\n",
        "df['qnt_tweets'] = df['conta'].apply(conta_tweets_user)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "ZVNwofo9mS4G",
        "outputId": "f077da8f-e3ce-47f5-fec7-d22370ac39c7"
      },
      "outputs": [],
      "source": [
        "# TRATAMENTO E VISUALIZAÇÃO DA QUANTIDADE DE TWEETS POR USUÁRIO\n",
        "\n",
        "# Eliminando os dados duplicados \n",
        "new_df = df.drop_duplicates(subset=['conta'])\n",
        "\n",
        "# Colocando os dados em ordem decrescente de acordom com a qtd de tweets\n",
        "result_new_df = new_df[['conta','qnt_tweets']].sort_values(by=['qnt_tweets'], ascending=False)\n",
        "result_new_df.reset_index(drop = True, inplace=True)\n",
        "\n",
        "# Imprmindo os 10 primeiros resultados\n",
        "#print(result_new_df.head(10))\n",
        "#print(' ')\n",
        "\n",
        "# Contando quantos usuários diferentes existem no dataframe\n",
        "print('Existem '+str(result_new_df.conta.count())\n",
        "      +' usuários no dataframe')\n",
        "\n",
        "# Contando quantos usuários tem 1 tweet no dataframe\n",
        "filtro_1 = result_new_df['qnt_tweets'] < 2\n",
        "new_result_1 = result_new_df[filtro_1]\n",
        "print(str(new_result_1.conta.count()) + ' usuários tem 1 tweet')\n",
        "\n",
        "# Contando quantos usuários tem mais de 5 tweets no dataframe\n",
        "filtro_5 = result_new_df['qnt_tweets'] >= 5 \n",
        "new_result_5 = result_new_df[filtro_5]\n",
        "print(str(new_result_5.conta.count()) + ' usuários tem 5 ou mais tweets')\n",
        "\n",
        "# Contando quantos usuários tem mais de 10 tweets no dataframe\n",
        "filtro_10 = result_new_df['qnt_tweets'] >= 10\n",
        "new_result_10 = result_new_df[filtro_10]\n",
        "print(str(new_result_10.conta.count()) + ' usuários tem 10 ou mais tweets')\n",
        "\n",
        "result_new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ogql68XdhG45",
        "outputId": "14a410e0-385c-4c22-ab7c-8349ccab4ee1"
      },
      "outputs": [],
      "source": [
        "# IPRIMINDO O BOXPLOT COM A QUANTIDADE DE TWEETS POR USUÁRIO\n",
        "sns.boxplot(x=result_new_df[\"qnt_tweets\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjAAc2Vb7rH1"
      },
      "outputs": [],
      "source": [
        "# FUNÇÕES PARA FILTRAR OS TWEETS DE ACORDO COM O USUÁRIO DE NOTÍCIA\n",
        "\n",
        "# Função para selecionar e classificar os tweets como notícias\n",
        "def select_contas_news(text, lista):\n",
        "  inicio = []\n",
        "  fim = []\n",
        "  text_temp = str(text)\n",
        "  text_temp = re.sub(r'[\"-,.:@?!&$]', ' ', text_temp)\n",
        "  text_temp = text_temp.lower()\n",
        "  text_temp = text_temp.split()\n",
        "  inicio.append(text_temp)\n",
        "  result = [word for word in text_temp if word.lower() not in lista]\n",
        "  fim.append(result)\n",
        "  if(np.array_equal(inicio,fim)==True):\n",
        "    return text\n",
        "  else:\n",
        "    return 'codigo_tweet_news'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "krM5XAo07r-B",
        "outputId": "9bed6a00-a578-42c5-e38f-3bd811952bc4"
      },
      "outputs": [],
      "source": [
        "# FILTRANDO OS TWEETS DE ACORDO COM O USUÁRIO\n",
        "# FILTRAGEM MANUAL REALIZADA PELO DIANSLEY\n",
        "\n",
        "# Adicionando os usuários que terão os tweets apagados\n",
        "users_news = []\n",
        "\n",
        "# Passando a lista de usuários para minúscula\n",
        "new_users_news = []\n",
        "for word in users_news:\n",
        "  word = word.lower()\n",
        "  new_users_news.append(word)\n",
        "\n",
        "# Aplicação da função para filtrar os contas de notícias\n",
        "new_data = data[['full_text','user']]\n",
        "new_data['user'] = new_data['user'].apply(select_contas_news, lista=new_users_news)\n",
        "\n",
        "# Filtra os tweets que não são de noticías\n",
        "filtro = new_data.user!='codigo_tweet_news'\n",
        "result_data_news = new_data[filtro]\n",
        "\n",
        "# Reset do indice do dataframe \n",
        "result_data_news.reset_index(drop = True, inplace=True)\n",
        "result_data_news['user'] = result_data_news['user'].apply(filtra_users)\n",
        "\n",
        "result_data_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hHxaGXG3xrH"
      },
      "outputs": [],
      "source": [
        "# FUNÇÕES PARA FILTRAR OS TWEETS DE ACORDO COM OS USUÁRIOS BOTS\n",
        "\n",
        "# Função para selecionar e classificar os tweets como notícias\n",
        "def select_contas_bots(text, lista):\n",
        "  inicio = []\n",
        "  fim = []\n",
        "  text_temp = str(text)\n",
        "  text_temp = re.sub(r'[\"-,.:@?!&$]', ' ', text_temp)\n",
        "  text_temp = text_temp.lower()\n",
        "  text_temp = text_temp.split()\n",
        "  inicio.append(text_temp)\n",
        "  result = [word for word in text_temp if word.lower() not in lista]\n",
        "  fim.append(result)\n",
        "  if(np.array_equal(inicio,fim)==True):\n",
        "    return text\n",
        "  else:\n",
        "    return 'codigo_tweet_bots'\n",
        "\n",
        "def compara_listas(lista1, lista2):\n",
        "    usuarios_noticias = []\n",
        "    contador = 0\n",
        "    for word1 in lista1:\n",
        "      if word1 in lista2:\n",
        "        contador = contador + 1\n",
        "    print('Existe '+str(contador)+' correspondências entres as listas'+ \n",
        "    ' de usuários de nóticia e usuários bots')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "EATnPpAw4PKt",
        "outputId": "db73ce58-582e-4be9-ac41-f10e171034ed"
      },
      "outputs": [],
      "source": [
        "# FILTRANDO OS TWEETS DE ACORDO COM O USUÁRIO BOTS\n",
        "# FILTRAGEM MANUAL REALIZADA PELO GEAN ATRAVÉS DO BOTOMETER\n",
        "\n",
        "# Adicionando os usuários que terão os tweets apagados\n",
        "users_bots = []               \n",
        "\n",
        "# Passando a lista de usuários para minúscula\n",
        "new_users_bots = []\n",
        "for word in users_bots:\n",
        "  word = word.lower()\n",
        "  new_users_bots.append(word)\n",
        "\n",
        "# Comparando as correspondências entre as listas de notícias com bots\n",
        "compara_listas(lista1=users_news, lista2=users_bots)\n",
        "\n",
        "# Aplicação da função para filtrar os contas de notícias\n",
        "result_data_news['user'] = result_data_news['user'].apply(select_contas_bots, lista=new_users_bots)\n",
        "\n",
        "# Filtra os tweets que não são de noticías\n",
        "filtro = result_data_news.user!='codigo_tweet_bots'\n",
        "result_data_bots = result_data_news[filtro]\n",
        "\n",
        "# Reset do indice do dataframe \n",
        "result_data_bots.reset_index(drop = True, inplace=True)\n",
        "\n",
        "result_data_bots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hUMBICpc5Xkt",
        "outputId": "4d4bc8f0-00e0-4e0c-e4e8-269a979d630d"
      },
      "outputs": [],
      "source": [
        "# BOXPLOT DATAFRAME APÓS REALIZR A ELIMINAÇÃO DOS USUÁRIOS DE NOTÍCIAS E BOTS\n",
        "\n",
        "# Função para contagem dos usúarios no agrupamento\n",
        "df_boxplot = result_data_bots\n",
        "df_boxplot['qnt_tweets'] = df_boxplot['user'].apply(conta_tweets_user)\n",
        "\n",
        "# Eliminando os dados duplicados \n",
        "df_boxplot = df_boxplot.drop_duplicates(subset=['user'])\n",
        "\n",
        "# Colocando os dados em ordem decrescente de acordom com a qtd de tweets\n",
        "df_boxplot = df_boxplot[['user','qnt_tweets']].sort_values(by=['qnt_tweets'], ascending=False)\n",
        "df_boxplot.reset_index(drop = True, inplace=True)\n",
        "\n",
        "# IMPRIMINDO A TABELA COM OS USUÁRIOS APÓS A LIMPEZA\n",
        "df_boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "OLKUoimM7RZ_",
        "outputId": "96813749-9a8f-4c46-92c6-7b3682b07896"
      },
      "outputs": [],
      "source": [
        "# IPRIMINDO O BOXPLOT APÓS A LIMPEZA DE USUÁRIOS\n",
        "sns.boxplot(x=df_boxplot[\"qnt_tweets\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJVDvCdgZUNE"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO PARA CONVERSÃO DE EMOJIS EM STRINGS\n",
        "\n",
        "# Função para converção de emojis em strings\n",
        "def convert_emojis(text):\n",
        "  text_temp = emoji.demojize(str(text), language='pt')\n",
        "  return text_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "V22HBCk5i1hr",
        "outputId": "fda6b012-acff-4c79-f678-aa99868acc8c"
      },
      "outputs": [],
      "source": [
        "# CONVERTENDO OS EMOJIS EM STRINGS\n",
        "\n",
        "# Aplicando a função de conversão de strings\n",
        "result_data_bots = result_data_bots[['full_text', 'user']]\n",
        "result_data_bots['full_text'] = result_data_bots['full_text'].apply(convert_emojis)\n",
        "\n",
        "# Tratamento das string geradas na conversão dos emojis\n",
        "result_data_bots['full_text'] = result_data_bots['full_text'].str.replace(':',' ')\n",
        "\n",
        "result_data_bots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJjt5GlGtKDl"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO PARA LIMPEZA DOS TWEETS \n",
        "def cleaning_text(text):\n",
        "  punctuation_stand = string.punctuation # Pontuações\n",
        "  punctuation_others = re.compile('<.*?>') # Pontos\n",
        "  urls = re.compile(r'@[a-z0-9_]+|http\\S+|www\\.\\S+') # Usuários e url's\n",
        "  text_temp = text.lower()\n",
        "  text_temp = punctuation_others.sub(r'', text_temp)\n",
        "  text_temp = text_temp.translate(str.maketrans('', '', string.digits)) #removendo numeros\n",
        "  text_temp = urls.sub(r'', text_temp)\n",
        "  text_temp = text_temp.translate(str.maketrans('','',punctuation_stand))\n",
        "  return text_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PFrXJ_Tbtc4E",
        "outputId": "0682bca6-b210-42cf-d649-7daf567a045e"
      },
      "outputs": [],
      "source": [
        "# LIMPEZA DOS TWEETS\n",
        "\n",
        "result_data_bots['full_text'] = result_data_bots['full_text'].apply(cleaning_text)\n",
        "\n",
        "result_data_bots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Kf2V3l1BkQoP",
        "outputId": "8bad445b-df20-4e92-cc1c-36018ed0cc62"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO PARA SUBSTITUIÇÃO DAS PALAVRAS\n",
        "def converte_palavras(palavra):\n",
        "  if palavra and palavra == 'n':\n",
        "    return 'nao'\n",
        "  elif palavra and palavra == 'hj':\n",
        "    return 'hoje'\n",
        "  elif palavra and ('kk' in palavra or 'rsrs' in palavra or 'rs' == palavra or 'haha' in palavra or 'hehe' in palavra):\n",
        "    return 'risos'\n",
        "  elif palavra and palavra == 'nd':\n",
        "    return 'nada'\n",
        "  elif palavra and palavra == 'ngm':\n",
        "    return 'ninguem'\n",
        "  elif palavra and palavra == 'pq':\n",
        "    return 'porque'\n",
        "  elif palavra and palavra == 'obg':\n",
        "    return 'obrigado'\n",
        "  elif palavra and palavra == 'sextou':\n",
        "    return 'sexta'\n",
        "  elif palavra and palavra == 'sdd':\n",
        "    return 'saudade'\n",
        "  elif palavra and palavra == 'mt':\n",
        "    return 'muito'\n",
        "  elif palavra and palavra == 'tmj':\n",
        "    return 'juntos'\n",
        "  elif palavra and palavra == 'pfvr':\n",
        "    return 'favor'\n",
        "  elif palavra and palavra == 'bb':\n",
        "    return 'bebe'\n",
        "  elif palavra and palavra == 'víru':\n",
        "    return 'virus'\n",
        "  elif palavra and (palavra == 'tá' or palavra == 'ta'):\n",
        "    return 'esta'\n",
        "  elif palavra and (palavra == 'tô' or palavra == 'to'):\n",
        "    return 'estou'\n",
        "  elif palavra and (palavra == 'udi' or palavra == 'udia'):\n",
        "    return 'uberlandia'\n",
        "  else:\n",
        "    return palavra\n",
        "\n",
        "# FUNÇÃO PARA CHAMAR A FUNÇÃO DE SUBSTITUIÇAO DAS PALAVRAS\n",
        "def substitui_palavras(text):\n",
        "  text_temp = text.split()\n",
        "  result = [converte_palavras(word) for word in text_temp]\n",
        "  return ' '.join(result)\n",
        "\n",
        "# CONVERSÃO DAS PALAVRAS\n",
        "result_data_bots['full_text'] = result_data_bots['full_text'].apply(substitui_palavras)\n",
        "result_data_bots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RT12QazkunF",
        "outputId": "0e48fb6e-12bf-43c8-ee64-1b7c50b0f396"
      },
      "outputs": [],
      "source": [
        "# Conta palavras antes do processo de eliminação de palavras 0,5% e 90%\n",
        "texto = []\n",
        "def criaTexto(text):\n",
        "  text_temp = str(text)\n",
        "  texto.append(text_temp)\n",
        "  return texto\n",
        "\n",
        "nuvem_palavras_1 = result_data_bots['full_text'].apply(criaTexto)\n",
        "new_texto = str(texto).strip('[]')\n",
        "len(new_texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-6-nZrsklfj"
      },
      "outputs": [],
      "source": [
        "def contemPalavraTweet(new_tweet, palavra):\n",
        "  if palavra in new_tweet:\n",
        "      return palavra\n",
        "  else:\n",
        "      return 'codigo'\n",
        "\n",
        "# Função para selecionar e classificar os tweets como notícias\n",
        "def contaQuantidade(palavra, new_tweet):\n",
        "  df = new_tweet.apply(contemPalavraTweet, palavra=palavra)\n",
        "  filtro = df!='codigo'\n",
        "  new_df = df[filtro]\n",
        "  contador = new_df.count()\n",
        "  return contador\n",
        "  \n",
        "\n",
        "def selecionaDados(tweet):\n",
        "  tweet_return = []\n",
        "  temp = str(tweet)\n",
        "  temp = temp.split()\n",
        "  new_tweet = result_data_bots['full_text']\n",
        "  len_df = result_data_bots['full_text'].count()\n",
        "  for palavra in temp:\n",
        "    cont = contaQuantidade(palavra, new_tweet)\n",
        "    if (cont < len_df*0.9):\n",
        "      if (cont > len_df*0.005):\n",
        "        tweet_return.append(palavra)\n",
        "  return ' '.join(tweet_return)\n",
        "\n",
        "result_data_bots['full_text'] = result_data_bots['full_text'].apply(selecionaDados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "MsauiMxwlGrR",
        "outputId": "06dbdc30-1a88-4392-f08e-cc7a1e9b6676"
      },
      "outputs": [],
      "source": [
        "# Conta palavras após o processo de eliminação de palavras 0,5% e 90%\n",
        "texto = []\n",
        "def criaTexto(text):\n",
        "  text_temp = str(text)\n",
        "  texto.append(text_temp)\n",
        "  return texto\n",
        "\n",
        "nuvem_palavras_1 = result_data_bots['full_text'].apply(criaTexto)\n",
        "new_texto = str(texto).strip('[]')\n",
        "new_texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crtdb-806yfa"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO PARA FILTRAR OS TWEETS DE ACORDO COM DETERMINADA ENTRADA \n",
        "\n",
        "# Função para selecionar e classificar os tweets\n",
        "def select_tweet_input(text, lista):\n",
        "  inicio = []\n",
        "  fim = []\n",
        "  text_temp = str(text)\n",
        "  text_temp = re.sub(r'[\"-,.:@?!&$]', ' ', text_temp)\n",
        "  text_temp = text_temp.lower()\n",
        "  text_temp = text_temp.split()\n",
        "  inicio.append(text_temp)\n",
        "  result = [word for word in text_temp if word.lower() not in lista]\n",
        "  fim.append(result)\n",
        "  if(np.array_equal(inicio,fim)==True):\n",
        "    return ' '.join(result)\n",
        "  else:\n",
        "    return 'codigo_tweet_selected'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3lhrIxas6yXV",
        "outputId": "22da26e4-1f6b-40bc-83dc-7d1f9783265b"
      },
      "outputs": [],
      "source": [
        "# FILTRANDO OS TWEETS DE ACORDO COM PALAVRAS NO TEXTO\n",
        "# Ex: Tweets que contenha a palavra BBB ou algum participante\n",
        "\n",
        "# Adicionando as palavras que serão filtradas\n",
        "words_input = []\n",
        "\n",
        "# Tranformando o result_data_bots em result_clean \n",
        "result_clean = result_data_bots\n",
        "\n",
        "# Aplicando a função para seleção dos \n",
        "result_clean['full_text'] = result_clean['full_text'].apply(select_tweet_input, lista=words_input)\n",
        "\n",
        "# Filtra os tweets que não foram selecionados\n",
        "filtro = result_clean.full_text!='codigo_tweet_selected'\n",
        "result_remove = result_clean[filtro]\n",
        "\n",
        "# Reset do indice do dataframe \n",
        "result_remove.reset_index(drop = True, inplace=True)\n",
        "\n",
        "result_remove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ7CSMEOIpzJ"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO PARA REMOVER DETERMINADAS PALAVRAS DOS TWEETS\n",
        "def remove_words(text,lista):\n",
        "  text_temp = text.split()\n",
        "  result = [word for word in text_temp if word.lower() not in lista]\n",
        "  result_temp = ' '.join(result)\n",
        "  return result_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dlZQXshpsPeL",
        "outputId": "889c352e-15e3-4279-8c3d-6ce151ff920d"
      },
      "outputs": [],
      "source": [
        "# REMOVENDO AS PALAVRAS DOS TWEETS\n",
        "# Ex: As palavras que foram utilizadas na coleta\n",
        "\n",
        "# Adicionando as palavras que serão removidas\n",
        "words_remove  = [ 'covid', 'covid19', 'coronavírus', 'coronavirus','pandemia',\n",
        "                 'brasil','covid19brasil','sobre','ainda','pra','vai','agora','aqui','hoje','todo',\n",
        "                  'dia','co','q','de','o','e','da','mil','um','a','que','uma',\n",
        "                 'dos', 'é','ela','na','em','tão','do','vc','todo','toda','só',\n",
        "                 'nada','tudo','no','pouco','por','nem','se','nos','para','antes',\n",
        "                 'faz','neste','quer','teve','depois','mas','há','mais','ano','diz',\n",
        "                 'covidbrasil','pessoa','ter','sobre','ainda','pra','vai','agora','aqui','hoje','todo',\n",
        "                  'dia','https','co','CO','c o','de','mil','pessoa',\n",
        "                  'tá', 'ir', 'fazer', 'poder', 'gente','falar', 'aí', 'dar',\n",
        "                  'bem', 'outro', 'algum', 'não', 'vir', \"…\", \"•\", \"“\", \"”\"]\n",
        "\n",
        "# Aplicando a função para remoção das palavras no tweet\n",
        "result_remove['full_text'] = result_remove['full_text'].apply(remove_words, lista=words_remove)\n",
        "\n",
        "result_remove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyY5PgSAPB-c"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "  text_temp = str(text)\n",
        "  stopwords = nltk.corpus.stopwords.words('portuguese') \n",
        "  newStopWords = []\n",
        "  stopwords.extend(newStopWords)\n",
        "  new_text = [word for word in text_temp.split() if word not in stopwords]\n",
        "  return ' '.join(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCi-Ro6YNESo"
      },
      "outputs": [],
      "source": [
        "# Calculando a frequência de cada palavra no dataframe com NLTK\n",
        "new_data_remove = result_remove['full_text']\n",
        "new_data_remove = new_data_remove.apply(remove_stopwords)\n",
        "\n",
        "sent = ' '.join(new_data_remove)\n",
        "frequencia = FreqDist(word.lower() for word in word_tokenize(sent))\n",
        "df_frequencia = pd.DataFrame({\"Palavras\": frequencia.keys(),\n",
        "                              \"Frequencia\": frequencia.values()})\n",
        "df_frequencia.nlargest(columns = \"Frequencia\", n = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ3WXBodQLfU"
      },
      "outputs": [],
      "source": [
        "# FUNÇÕES PARA TOKENIZAR, ELIMINAR STOPWORDS E LEMANTIZAR\n",
        "\n",
        "# Função para lemantizar as palavras\n",
        "def lemmatization(text):\n",
        "  nlp = spacy.load('pt')\n",
        "  text_temp = str(text)\n",
        "  doc = nlp(text_temp)\n",
        "  words_lemma = [token.lemma_ for token in doc]\n",
        "  return ' '.join(words_lemma)\n",
        "\n",
        "# Função para tokenizar e eliminar stopwords\n",
        "def tokenized_words(text):\n",
        "  text_temp = str(text)\n",
        "  stopwords = nltk.corpus.stopwords.words('portuguese') # Stopwords\n",
        "  stopwords.extend(words_remove)\n",
        "  tokens = [word for word in text_temp.split() if word not in stopwords]\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8LFbKCFyplL",
        "outputId": "abc8cbbd-d2e4-43d4-88c9-51b358bc1a61"
      },
      "outputs": [],
      "source": [
        "# TOKENIZAÇÃO E LEMATIZAÇÃO DOS TWEETS\n",
        "\n",
        "# Lematização dos tweets\n",
        "result_remove['full_text'] = result_remove['full_text'].apply(lemmatization)\n",
        "\n",
        "# Tokenização dos tweets\n",
        "tokens = result_remove['full_text'].apply(tokenized_words)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx07luE3zH3S"
      },
      "outputs": [],
      "source": [
        "# Construção do dicionário e do corpo do modelo\n",
        "dictionary = corpora.Dictionary(tokens)\n",
        "corpus = [dictionary.doc2bow(text) for text in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGlIIQBa6uxA"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo LDA\n",
        "ldamodel = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "Zgc60ONJICrp",
        "outputId": "3695982f-6a33-4858-defe-cf6ac4d4a802"
      },
      "outputs": [],
      "source": [
        "# Visualização interativa dos tópicos \n",
        "vis_data = gensimvis.prepare(ldamodel, corpus, dictionary)\n",
        "pyLDAvis.display(vis_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQnJvNDxgzLI",
        "outputId": "e3ae3ec0-bc0c-4c28-aaf9-0c49ae108de7"
      },
      "outputs": [],
      "source": [
        "# Print dos tópicos \n",
        "ldamodel = ldamodel.show_topics(num_words=4)\n",
        "\n",
        "for topic in ldamodel:\n",
        "    print(topic)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
